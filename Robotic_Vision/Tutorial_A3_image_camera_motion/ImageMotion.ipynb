{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "  <tr>\n",
    "      <td><div align=\"left\"><font size=\"20\" >Camera and image motion</font></div></td>\n",
    "     <td><img src=\"images/RVSS-logo.png\" width=\"400\"></td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to import some modules. We will use the standard `numpy` package to help us with linear algebraic operations on matrices and vectors.\n",
    "\n",
    "`common.py` is a set of specific helper functions to support these tutorials.  If you want to know what a function does, just click somewhere within the parentheses that enclose the arguments and hit SHIFT+TAB. If there's a + button at the top of the popup tooltip, this means the documentation spans a few lines, click it to show the full docstring, then scroll up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: machinevision-toolbox-python==0.5.5 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (0.5.5)\n",
      "Requirement already satisfied: ansitable in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from machinevision-toolbox-python==0.5.5) (0.9.5)\n",
      "Requirement already satisfied: scipy in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from machinevision-toolbox-python==0.5.5) (1.4.1)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from machinevision-toolbox-python==0.5.5) (1.19.5)\n",
      "Requirement already satisfied: opencv-python in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from machinevision-toolbox-python==0.5.5) (4.2.0.32)\n",
      "Requirement already satisfied: spatialmath-python in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from machinevision-toolbox-python==0.5.5) (0.8.9)\n",
      "Requirement already satisfied: matplotlib in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from machinevision-toolbox-python==0.5.5) (3.1.3)\n",
      "Requirement already satisfied: colored in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from ansitable->machinevision-toolbox-python==0.5.5) (1.4.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from matplotlib->machinevision-toolbox-python==0.5.5) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from matplotlib->machinevision-toolbox-python==0.5.5) (1.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from matplotlib->machinevision-toolbox-python==0.5.5) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from matplotlib->machinevision-toolbox-python==0.5.5) (2.8.1)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from cycler>=0.10->matplotlib->machinevision-toolbox-python==0.5.5) (1.15.0)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib->machinevision-toolbox-python==0.5.5) (45.2.0.post20200210)\n",
      "\u001b[33mWARNING: You are using pip version 20.3.3; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/mxnet_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "\n",
    "!{sys.executable} -m pip install machinevision-toolbox-python==0.5.5\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from machinevisiontoolbox import CentralCamera\n",
    "from spatialmath import SE3\n",
    "import scipy.linalg as lin\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "np.set_printoptions(linewidth=120, formatter={'float': lambda x: f\"{x:8.4g}\" if abs(x) > 1e-10 else f\"{0:8.4g}\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Relationship between camera and image-plane motion\n",
    "Instantiate a projective camera object, centred at the origin and viewing parallel to the world frame z-axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "principal point not specified,                    setting it to centre of image plane\n",
      "           Name: MVTB camera [CentralCamera]\n",
      "     pixel size: 1e-05 x 1e-05\n",
      "     image size: 1024.0 x 1024.0\n",
      "           pose: t = 0, 0, 0; rpy/zyx = 0°, 0°, 0°\n",
      "   principal pt: (512.0, 512.0)\n",
      "   focal length: (0.008, 0.008)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "camera = CentralCamera()\n",
    "print(camera)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a point in the world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = [1, 1, 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will project it to the image plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[     672],\n",
       "       [     672]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p0 = camera.project(P)\n",
    "p0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if we displace the camera slightly (distance `d`) in the x-direction the pixel coordinates will become"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[     656],\n",
       "       [     672]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = 0.1\n",
    "px = camera.project(P, pose=SE3([d, 0, 0]))\n",
    "px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the camera coordinate conventions of RVC2 Fig. 11.5, the camera has moved to the right so the image point has moved to the left. The sensitivity of image motion to camera motion is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    -160],\n",
       "       [       0]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "( px - p0) / d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which is an approximation to the partial derivative $\\partial p / \\partial x$. It shows that 1 m of camera motion would lead to −160 pixel of feature motion in the u-direction. \n",
    "\n",
    "We can repeat this for z-axis translation, ie. moving the camera forward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   32.65],\n",
       "       [   32.65]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "( camera.project(P, pose=SE3([0, 0, d])) - p0) / d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which is an approximation to the partial derivative $\\partial p / \\partial z$, and  shows equal motion in the u- and v-directions\n",
    "\n",
    "We can also rotate the camera about the x-axis, equivalent to pitching the camera upwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   40.96],\n",
       "       [   851.9]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "px = camera.project(P, pose=SE3.Rx(d))\n",
    "( px - p0) / d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which is predominantly motion down in the image, remember the v-axis points down in the image. the image motion is predominantly in the v-direction. It is clear that camera motion along and about the different degrees of freedom in SE(3) causes quite different motion of image points.\n",
    "\n",
    "## Things to try on your own\n",
    "1. use a smaller value of `d` when computing the numerical approximation to the Jacobian\n",
    "\n",
    "# Image Jacobian\n",
    "\n",
    "Consider the camera as a function \n",
    "\\begin{equation}\n",
    "p = {\\cal P}(P, \\mathbf{K}, \\xi)\n",
    "\\end{equation}\n",
    "where $p \\in \\mathbb{R}^2$ is the image-plane point, $P \\in \\mathbb{R}^3$ is the world point, $\\mathbf{K} \\in \\mathbb{R}^{3 \\times 3}$ is the camera intrinsics and $\\xi \\in SE(3)$ is the camera pose. Its derivative with respect to time is\n",
    "\\begin{equation}\n",
    "\\dot{p} = \\mathbf{J}_p(P, \\mathbf{K}, \\xi) \\nu\n",
    "\\end{equation}\n",
    "where $\\nu = (v_x, v_y, v_z, \\omega_x, \\omega_y, \\omega_z) \\in \\mathbb{R}^6$ is the velocity of the camera -- the spatial velocity.\n",
    "\n",
    "$\\mathbf{J}_p$ is a Jacobian-like object, but because we have taken the derivative with respect to a pose $\\xi \\in SE(3)$ rather than a vector it is technically called an _interaction matrix_. However in the visual servoing world it is more commonly called an _image Jacobian_ or a _feature sensitivity matrix_.\n",
    "\n",
    "The Toolbox CentralCamera class provides the method visjac_p to compute the image Jacobian and for the example above it is\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    -160,        0,       32,       32,     -832,      160],\n",
       "       [       0,     -160,       32,      832,      -32,     -160]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J = camera.visjac_p( (672, 672), 5)\n",
    "J\n",
    "\n",
    "# Image jacobian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each column gives the image-plane velocity for the corresponding component of camera velocity, ie. the first column corresponds to camera x-axis motion, the second column corresponds to camera x-axis motion and the last column correpsonds to camera z-axis rotation.  In Out[6] we computed a numerical approximation to the first column,  Out[7] an approximation to the third column, and Out[8] is an approximation to the fourth column.\n",
    "\n",
    "If the camera is moving at 1m/s in the x-axis direction the velocity at the pixel will be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    -160,        0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J @ [1, 0, 0, 0, 0, 0]\n",
    "\n",
    "# Velocity screw with pure x-translational motion\n",
    "# This number cooresponds with the approximate jacobian computed earlier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in units of pixel/s.\n",
    "\n",
    "If the velocity was 1rad/s around the z-axis the velocity at the pixel will be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([     160,     -160])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J @ [0, 0, 0, 0, 0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and if the camera velocity was 1m/s in the x-axis direction *and* 1rad/s in around the z-axis the velocity at the pixel will be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([       0,     -160])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J @ [1, 0, 0, 0, 0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optical flow fields\n",
    "\n",
    "We just computed the image Jacobian for a single point close to the centre of the image plane.  Imagine now that we compute it for a grid over the image plane and then see how the image-plane velocity at each point varies with camera veloicty.\n",
    "\n",
    "The example below provides you with a slider for each component of camera velocity.  As you adjust them the corresponding optical flow field is displayed. Have a play and try to understand what this is showing you.  What happens if you motion in several dimensions of the camera velocity space?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "principal point not specified,                    setting it to centre of image plane\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "640d42ba08d1416d8e9b3b11a6a5357c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.5, description='X:', max=1.0, min=-1.0), FloatSlider(value=0.0, desc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "\n",
    "camera = CentralCamera() # create camera object\n",
    "\n",
    "\n",
    "@widgets.interact\n",
    "def animate( x =  widgets.FloatSlider(value=0.5, description='X:',  min=-1, max=1),\n",
    "             y =  widgets.FloatSlider(value=0,   description='Y:',  min=-1, max=1),\n",
    "             z =  widgets.FloatSlider(value=0,   description='Z:',  min=-1, max=1),\n",
    "             rx = widgets.FloatSlider(value=0,   description='rX:', min=-1, max=1),\n",
    "             ry = widgets.FloatSlider(value=0,   description='rY:', min=-1, max=1),\n",
    "             rz = widgets.FloatSlider(value=0,   description='rZ:', min=-1, max=1) ):\n",
    "\n",
    "    Z = 2  # distance to the grid of points\n",
    "    vel = [x, y, z, rx, ry, rz]  # camera velocity from sliders, as a column vector\n",
    "    \n",
    "    # setup the plot window, fixed scale, unity aspect ratio, grid lines on\n",
    "    plt.figure(figsize=(8,8))\n",
    "    ax = plt.gca()\n",
    "    plt.grid(True)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_facecolor('yellow')\n",
    "    plt.xlabel('u (pixels)')\n",
    "    plt.ylabel('v (pixels)')\n",
    "    plt.title('Velocity on camera image plane')\n",
    "    plt.xlim(0, 1000)\n",
    "    ax.set_ylim(1000, 0)  # inverted y-axis\n",
    "\n",
    "\n",
    "    # compute optical flow over a grid of points\n",
    "    a = np.arange(-1000, 1000, 50)  # set of flow points\n",
    "\n",
    "    [U, V] = np.meshgrid(a, a, indexing='ij')\n",
    "    du = np.empty(U.shape)\n",
    "    dv = np.empty(U.shape)\n",
    "    \n",
    "    for i in range(U.shape[1]):\n",
    "        for j in range(U.shape[0]):\n",
    "            pdot = camera.visjac_p( ([U[i,j], V[i,j]]), Z) @ vel\n",
    "            du[i,j] = pdot[0]\n",
    "            dv[i,j] = pdot[1]\n",
    "\n",
    "    # plot the flow vectors\n",
    "    #  -dv is to overcome a bug with quiver and flipped vertical axis\n",
    "    plt.quiver(U, V, du, -dv, scale=8000)\n",
    "    \n",
    "    \n",
    "    # Look what happens when you change our X with rX value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Things to try on your own\n",
    "1. Change the camera to a 4mm focal length, and see the change in the shape of the optical flow fields for rotation about the x- and y-axes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imperceptible motion\n",
    "Define a point in the world and compute its image Jacobian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = [0, 0, 5]\n",
    "p = camera.project(P)\n",
    "J = camera.visjac_p( p, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Jacobian is $2 \\times 6$ which means it has a nullity of 4, that is, there are four possible velocities that will cause zero image plane motion, as will any linear combination of these velocities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 4)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = lin.null_space(J)\n",
    "N.shape\n",
    "\n",
    "# Compute null space, which is a 6x4 matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can quickly verify this is the case for the first column which is a camera velocity of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([       0,        0,        1,        0,        0,        0])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N[:,0]\n",
    "\n",
    "# This shows that a translational motion in the Z dirrection will cause no motion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the resulting image-plane velocity is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([       0,        0])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J @ N[:,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([       0,   0.9806,        0,   0.1961,        0,        0])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N[:,1]\n",
    "# If we had mostly translational in the Y, and a bit in Z, we'd have no motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([       0,        0])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J @ N[:,0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which is effectively zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ambiguous motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    -160,        0,       32,       32,     -832,      160],\n",
       "       [       0,     -160,       32,      832,      -32,     -160]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P = [1, 1, 5]\n",
    "p = camera.project(P)\n",
    "J = camera.visjac_p( p, 5)\n",
    "J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66d04455e31c4ee78e944e0ed165696b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=8.0, description='f (mm): ', min=1.0), Output()), _dom_classes=('widge…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.set_printoptions(precision=3, floatmode='maxprec')\n",
    "np.set_printoptions(suppress=True)\n",
    "@widgets.interact\n",
    "def animate( f =  widgets.FloatSlider(value=8, description='f (mm): ',  min=1, max=100) ):\n",
    "    camera = CentralCamera(f=f*1e-3) # create camera object\n",
    "    p = camera.project(P)\n",
    "    J = camera.visjac_p( p, 5)\n",
    "    print(J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
